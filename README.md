ì¢‹ì•„. ì•„ë˜ëŠ” **ë‚´ê°€ ìƒê°í•˜ëŠ” â€œREADME í•˜ë‚˜ë¡œ ëë‚´ëŠ” ìµœìƒì¹˜ ë²„ì „â€**ì´ì•¼.
ğŸ‘‰ **labml ìŠ¤íƒ€ì¼ì˜ ë…¼ë¦¬ íë¦„**ì„ ìœ ì§€í•˜ë©´ì„œ
ğŸ‘‰ **GitHubì—ì„œ ë°”ë¡œ ê´€ë¦¬ ê°€ëŠ¥í•œ Markdown**ì´ê³ 
ğŸ‘‰ **ìˆ˜ì‹/ìš©ì–´ëŠ” ì˜ì–´, ì„¤ëª…ì€ í•œêµ­ì–´ ë³‘ê¸°**
ğŸ‘‰ **ë…¼ë¬¸ â†’ ì½”ë“œ â†’ CIFAR-10 ì‹¤ìŠµ**ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ë„ë¡ ì„¤ê³„í–ˆì–´.

ì´ê±¸ **ê·¸ëŒ€ë¡œ `README.md`ë¡œ ë‘ê³ **, ë§ˆìŒì— ì•ˆ ë“œëŠ” ë¶€ë¶„ë§Œ ê¹ì•„ë‚˜ê°€ë©´ ë¼.

---

# Deep Residual Learning for Image Recognition (ResNet) â€” Cheatsheet

> **Paper**: *Deep Residual Learning for Image Recognition*
> **Framework**: PyTorch
> **Architecture**: ResNet v1 (post-activation)
> **Goal**: ë…¼ë¬¸ê³¼ 1:1ë¡œ ë§¤í•‘ë˜ëŠ” reference êµ¬í˜„ + CIFAR-10 ì‹¤ìŠµìœ¼ë¡œì˜ ìì—°ìŠ¤ëŸ¬ìš´ í™•ì¥

---

## Why this document?

This repository is a **paper-faithful ResNet v1 cheatsheet**.

* ìˆ˜ì‹ â†’ ê°œë… â†’ ì½”ë“œê°€ **í•œ ì¤„ì”© ëŒ€ì‘**ë˜ë„ë¡ êµ¬ì„±
* ImageNet ë…¼ë¬¸ êµ¬ì¡°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„¤ëª…í•œ ë’¤,
* **ê°™ì€ blockì„ ìœ ì§€í•œ ì±„ CIFAR-10 ì‹¤ìŠµìœ¼ë¡œ í™•ì¥**

> **KR ìš”ì•½**
> â€œResNet ë…¼ë¬¸ì„ ì½ë‹¤ê°€ êµ¬í˜„ìœ¼ë¡œ ì˜®ê¸¸ ë•Œ,
> â€˜ì–´ë””ê°€ ë…¼ë¬¸ì—ì„œ ë‚˜ì˜¨ ê±°ê³ , ì–´ë””ê°€ ì‹¤ì „ ë³€í˜•ì¸ì§€â€™ í—·ê°ˆë¦¬ì§€ ì•Šê²Œ ë§Œë“œëŠ” ë¬¸ì„œâ€

---

## 1. Degradation Problem

Deep neural networks suffer from the **degradation problem**:

> As network depth increases, training error **increases**, even though the model is strictly more expressive.

* **KR ì„¤ëª…**
  ë‹¨ìˆœíˆ layerë¥¼ ë” ìŒ“ëŠ”ë‹¤ê³  ì„±ëŠ¥ì´ ì¢‹ì•„ì§€ì§€ ì•ŠëŠ”ë‹¤.
  ì˜¤íˆë ¤ ê¹Šì–´ì§ˆìˆ˜ë¡ **í•™ìŠµ ìì²´ê°€ ì–´ë ¤ì›Œì§€ê³  ì •í™•ë„ê°€ ë–¨ì–´ì§€ëŠ” í˜„ìƒ**ì´ ë°œìƒí•œë‹¤.

The paper argues that **deeper models should not perform worse** than shallower ones,
because extra layers could simply learn an **identity mapping**.

---

## 2. Residual Learning

Instead of directly learning a mapping ( \mathcal{H}(x) ),
ResNet learns a **residual function**:

[
\mathcal{F}(x) = \mathcal{H}(x) - x
]

so that the original mapping becomes:

[
\mathcal{H}(x) = \mathcal{F}(x) + x
]

* **KR ì§ê´€**
  â€œì™„ì „íˆ ìƒˆ í•¨ìˆ˜ë¥¼ í•™ìŠµâ€í•˜ëŠ” ëŒ€ì‹ 
  **ì…ë ¥ê³¼ì˜ ì°¨ì´(residual)** ë§Œ í•™ìŠµí•˜ê²Œ í•˜ë©´ í›¨ì”¬ ì‰½ë‹¤.
* Identity mappingì€ ( \mathcal{F}(x) = 0 ) ë§Œ í•™ìŠµí•˜ë©´ ëœë‹¤.

---

## 3. Projection Shortcut

When the shapes of ( \mathcal{F}(x) ) and ( x ) differ
(spatial size or number of channels):

[
\mathcal{H}(x) = \mathcal{F}(x) + W_s x
]

* **KR ì„¤ëª…**

  * feature mapì˜ **HÃ—W** ë˜ëŠ” **C** ê°€ ë‹¤ë¥´ë©´ ë‹¨ìˆœíˆ ë”í•  ìˆ˜ ì—†ë‹¤.
  * ì´ë•Œ ë…¼ë¬¸ì€ **learned linear projection** (W_s) ë¥¼ ì œì•ˆí•œë‹¤.
* Zero-paddingë³´ë‹¤ **projectionì´ ë” ì¢‹ì€ ì„±ëŠ¥**ì„ ë³´ì˜€ë‹¤ê³  ë³´ê³ í•¨.

---

## 4. Code Mapping â€” Projection Shortcut

```python
class ShortcutProjection(nn.Module):
    """
    Linear projection: W_s x
    """
    def __init__(self, in_channels, out_channels, stride):
        super().__init__()
        self.conv = nn.Conv2d(
            in_channels, out_channels,
            kernel_size=1, stride=stride, bias=False
        )
        self.bn = nn.BatchNorm2d(out_channels)

    def forward(self, x):
        return self.bn(self.conv(x))
```

* **ë…¼ë¬¸ ëŒ€ì‘**

  * ( W_s x )
* **KR í¬ì¸íŠ¸**

  * strideë¥¼ main pathì™€ ë™ì¼í•˜ê²Œ ì ìš© â†’ spatial size ì¼ì¹˜
  * BNì€ ë…¼ë¬¸ì—ì„œ ê¶Œì¥ë¨

---

## 5. ResNet v1 Block (Post-activation)

### BasicBlock (ResNet-18 / 34)

**Pattern (v1)**

```
Conv â†’ BN â†’ ReLU
Conv â†’ BN
+ shortcut
ReLU
```

```python
class BasicBlockV1(nn.Module):
    def __init__(self, in_ch, out_ch, stride):
        super().__init__()
        self.conv1 = nn.Conv2d(in_ch, out_ch, 3, stride=stride, padding=1, bias=False)
        self.bn1   = nn.BatchNorm2d(out_ch)
        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, stride=1, padding=1, bias=False)
        self.bn2   = nn.BatchNorm2d(out_ch)

        if stride != 1 or in_ch != out_ch:
            self.shortcut = ShortcutProjection(in_ch, out_ch, stride)
        else:
            self.shortcut = nn.Identity()

    def forward(self, x):
        s = self.shortcut(x)
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        return F.relu(out + s)
```

* **KR í•µì‹¬**

  * shortcut ì¡°ê±´ì€ **stride ë³€ê²½ OR ì±„ë„ ë³€ê²½**
  * ë§ì…ˆ ì´í›„ ReLU â†’ **ResNet v1 (post-activation)**

---

## 6. Bottleneck Block (ResNet-50 / 101 / 152)

**Pattern (traditional v1)**

```
1Ã—1 â†’ BN â†’ ReLU
3Ã—3 â†’ BN â†’ ReLU   (stride here)
1Ã—1 â†’ BN
+ shortcut
ReLU
```

* **KR ì„¤ëª…**

  * 3Ã—3 ì—°ì‚°ì„ **bottleneck channel**ì—ì„œ ìˆ˜í–‰
  * ê³„ì‚°ëŸ‰ ê°ì†Œ + ê¹Šì€ ë„¤íŠ¸ì›Œí¬ ê°€ëŠ¥
* strideë¥¼ 3Ã—3ì— ì£¼ëŠ” ë°©ì‹ì€ **ì „í†µì (ë…¼ë¬¸ ê³„ì—´) êµ¬í˜„**

---

## 7. Stage & Downsampling Rule (ì¤‘ìš”)

**Paper rule (Table-style)**

* Downsampling (`stride=2`) happens **only at the first block of a new stage**
* Except for the **first stage**, which uses `stride=1`

| Stage  | Common name | First block stride |
| ------ | ----------- | ------------------ |
| layer1 | conv2_x     | 1                  |
| layer2 | conv3_x     | 2                  |
| layer3 | conv4_x     | 2                  |
| layer4 | conv5_x     | 2                  |

* **KR ì£¼ì˜**

  * `len(blocks)` ê°™ì€ ëˆ„ì  ë¸”ë¡ ê¸°ì¤€ì€ ë…¼ë¬¸ ê·œì¹™ì„ êµ¬í˜„í•  ìˆ˜ ì—†ë‹¤.
  * ë°˜ë“œì‹œ **stage index ê¸°ì¤€**ìœ¼ë¡œ strideë¥¼ ê²°ì •í•´ì•¼ í•œë‹¤.

---

## 8. ImageNet Stem (Paper-faithful)

```python
class StemImageNetV1(nn.Module):
    def __init__(self, in_ch=3, out_ch=64):
        super().__init__()
        self.conv = nn.Conv2d(in_ch, out_ch, 7, stride=2, padding=3, bias=False)
        self.bn   = nn.BatchNorm2d(out_ch)
        self.pool = nn.MaxPool2d(3, stride=2, padding=1)

    def forward(self, x):
        x = F.relu(self.bn(self.conv(x)))
        return self.pool(x)
```

* **ë…¼ë¬¸ Table 1 ê·¸ëŒ€ë¡œ**
* ImageNet ì…ë ¥(224Ã—224)ì— ìµœì í™”ëœ stem

---

## 9. From Paper to CIFAR-10

ë…¼ë¬¸ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ CIFAR-10(32Ã—32)ì— ì“°ë©´ **ë„ˆë¬´ ë¹¨ë¦¬ ë‹¤ìš´ìƒ˜í”Œë§**ëœë‹¤.

ê·¸ë˜ì„œ ì‹¤ìŠµì—ì„œëŠ” ë³´í†µ:

### CIFAR Stem

```python
class StemCIFAR(nn.Module):
    def __init__(self, in_ch=3, out_ch=64):
        super().__init__()
        self.conv = nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1, bias=False)
        self.bn   = nn.BatchNorm2d(out_ch)

    def forward(self, x):
        return F.relu(self.bn(self.conv(x)))
```

* **KR ìš”ì•½**

  * block / shortcut / stage ê·œì¹™ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
  * **stemê³¼ classifierë§Œ êµì²´**

---

## 10. Global Average Pooling

Instead of fixed-size pooling:

```python
nn.AdaptiveAvgPool2d(1)
```

* **KR ì„¤ëª…**

  * ì…ë ¥ í¬ê¸°ì— ë…ë¦½ì 
  * CIFAR / ImageNet ëª¨ë‘ ë™ì¼ ì½”ë“œ ì‚¬ìš© ê°€ëŠ¥

---

## 11. CIFAR-10 Training Skeleton

> ì¹˜íŠ¸ì‹œíŠ¸ ëª©ì ì´ë¯€ë¡œ í•µì‹¬ë§Œ ì •ë¦¬

* **Data augmentation**

  * `RandomCrop(32, padding=4)`
  * `RandomHorizontalFlip()`
* **Optimizer**

  * SGD(lr=0.1, momentum=0.9, weight_decay=2e-4)
* **Loss**

  * CrossEntropyLoss

---

## Final Notes

* This README follows **ResNet v1 (He et al., 2015)** faithfully.
* CIFAR-10 implementation is a **controlled deviation**, not a different model.
* If you understand every section here,
  you can **read the paper and write the code without guessing**.

---

### Suggested next steps

* Split this README into `docs/` if it grows
* Add stage-wise feature map size tables
* Add ResNet-18 / 50 config presets

---

ì›í•˜ë©´ ë‹¤ìŒìœ¼ë¡œ:

* ğŸ”¹ **ì´ README ê¸°ì¤€ìœ¼ë¡œ â€œë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì‚­ì œ ë²„ì „â€**
* ğŸ”¹ **stageë³„ shape í‘œ ì¶”ê°€**
* ğŸ”¹ **A/B ì½”ë“œì™€ ì •í™•íˆ ë§¤ì¹­ë˜ëŠ” ì£¼ì„ diff**

ì¤‘ ì•„ë¬´ê±°ë‚˜ ë°”ë¡œ ì´ì–´ì„œ í•´ì¤„ê²Œ.
